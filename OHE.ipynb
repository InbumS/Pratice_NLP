{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OHE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLhr7YJ2Ux+E3LEKIrGhA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InbumS/Pratice_NLP/blob/master/OHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#원-핫 인코딩(One-Hot Encoding) = 단어 집합(vocabulary) 문자를 숫자, 더 나아가 벡터로 바꾸는 기법"
      ],
      "metadata": {
        "id": "EUKrDL76LhtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRJvRCo7LWwM"
      },
      "outputs": [],
      "source": [
        "#원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, \n",
        "#다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. \n",
        "#이렇게 표현된 벡터를 원-핫 벡터(One-Hot vector)라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Okt  \n",
        "\n",
        "okt = Okt()  \n",
        "tokens = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDODOhnjMZ6y",
        "outputId": "5efe3ebb-5d10-4be8-eab5-6d7c2648c560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n",
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#보통 빈도수 단위로 정수를 분류한다.\n",
        "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
        "print('단어 집합 :',word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJemnG9BN6MJ",
        "outputId": "6cbfe8bc-eaa0-4cd2-c419-807a47408786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word, word_to_index):\n",
        "  one_hot_vector = [0]*(len(word_to_index))\n",
        "  index = word_to_index[word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector"
      ],
      "metadata": {
        "id": "UtyeGcEqOKzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding(\"자연어\", word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73_E-cbUOkwq",
        "outputId": "7648a052-dc18-4891-ce30-56f2eff2b3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keras를 이용한 One-Hot Encoding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "print('단어 집합 :',tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1VoOeEbX20S",
        "outputId": "c5253f3f-fe94-401b-e2f4-624f435cec5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#texts_to_sequences()를 통해서 이를 정수 시퀀스로 변환\n",
        "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
        "print(encoded)\n",
        "\n",
        "#keras의 정수인코딩으로부터의 원 핫 인코딩\n",
        "one_hot = to_categorical(encoded)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxfijy2CYkl5",
        "outputId": "88f8bafc-94f3-40b2-e563-b8b50d1a1a04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어간 유사성을 표현하지 못하는 단점과 단어가 늘수록 벡터 차원이 증가하므로 저장적인 측면에서 효율이 떨어진다\n",
        "#대안: 다차원 공간에서의 벡터화-> LSA(잠재 의미 분석//토픽 모델링),HAL\n",
        "#      예측기반에서의 벡터화->NNLM,RNNLM등\n",
        "\n",
        "#카운터 기반+ 예측기반의 워드 임베딩 ->GloVe\n"
      ],
      "metadata": {
        "id": "t0aP74HBbi5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}